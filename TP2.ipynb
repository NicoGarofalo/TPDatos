{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W6bWqgOVmrjA"
      },
      "source": [
        "# Notebook oficial - TP Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UYz7IWPLjiM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ec39bb1-e108-478b-e0f4-36d26c7b30c6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IKyPFVKemrAK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "abaf1c5d-4ace-4421-ec5a-93878f995334"
      },
      "source": [
        "# Importando librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import datetime\n",
        "import warnings\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#Modelos\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "f6mA5AutJ3vC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "666a295a-0b18-4ac1-fc6b-a00f905ecdf8"
      },
      "source": [
        "#Carga del dataset\n",
        "df_train = pd.read_csv('/content/drive/My Drive/datasetTPDatos/data/train.csv')\n",
        "df_test = pd.read_csv('/content/drive/My Drive/datasetTPDatos/data/test.csv')\n",
        "#Dimension\n",
        "print('La dimension del dataset es: ',df_train.shape[0], 'registros,', df_train.shape[1],'columnas')\n",
        "# Vista de los primeros registros\n",
        "df_train.head(5)\n",
        "# Data:\n",
        "# id - identificador unico para cada tweet\n",
        "# keyword - un keyword para el tweet (podría faltar)\n",
        "# location - ubicación desde donde fue enviado (podría no estar)\n",
        "# text - el texto del tweet\n",
        "# target - indica si se trata de un desastre real (1) o no (0)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "La dimension del dataset es:  7613 registros, 5 columnas\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoAn4tXyJ3vJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Definición de tipos\n",
        "df_train['id'] = df_train['id'].astype(int)\n",
        "df_train['keyword'] = df_train['keyword'].fillna(value = \"noKeyword\").astype('object')\n",
        "df_train['location'] = df_train['location'].astype('object')\n",
        "df_train['text'] = df_train['text'].astype('object')\n",
        "df_train['target'] = df_train['target'].astype('bool')\n",
        "df_test['id'] = df_test['id'].astype(int)\n",
        "df_test['keyword'] = df_test['keyword'].fillna(value = \"noKeyword\").astype('object')\n",
        "df_test['location'] = df_test['location'].astype('object')\n",
        "df_test['text'] = df_test['text'].astype('object')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ySjCAJbJ3vM",
        "colab_type": "text"
      },
      "source": [
        "## Filtrado de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzTJ3rr0J3vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Elimino duplicados\n",
        "df_train.drop_duplicates(inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoF6UbmNJ3vP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "03ea5061-6771-483c-ce25-f6e4fd4bad09"
      },
      "source": [
        "df_train.describe(include=\"all\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7613.000000</td>\n",
              "      <td>7613</td>\n",
              "      <td>5080</td>\n",
              "      <td>7613</td>\n",
              "      <td>7613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>222</td>\n",
              "      <td>3341</td>\n",
              "      <td>7503</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>noKeyword</td>\n",
              "      <td>USA</td>\n",
              "      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>61</td>\n",
              "      <td>104</td>\n",
              "      <td>10</td>\n",
              "      <td>4342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5441.934848</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>3137.116090</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2734.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5408.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>8146.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10873.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  id  ... target\n",
              "count    7613.000000  ...   7613\n",
              "unique           NaN  ...      2\n",
              "top              NaN  ...  False\n",
              "freq             NaN  ...   4342\n",
              "mean     5441.934848  ...    NaN\n",
              "std      3137.116090  ...    NaN\n",
              "min         1.000000  ...    NaN\n",
              "25%      2734.000000  ...    NaN\n",
              "50%      5408.000000  ...    NaN\n",
              "75%      8146.000000  ...    NaN\n",
              "max     10873.000000  ...    NaN\n",
              "\n",
              "[11 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUxtPrj5J3vS",
        "colab_type": "text"
      },
      "source": [
        "Hay algunos registros cuyo label es incorrecto, los corregimos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "557t51xOJ3vS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "469aefbc-ff6a-45aa-9044-d078227456a3"
      },
      "source": [
        "mislabelled_ids = [328,443,513,2619,3640,3900,4342,5781,6552,6554,6570,6701,6702,6729,6861,7226]\n",
        "\n",
        "df_train.loc[ df_train['id'].isin(mislabelled_ids)]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>328</td>\n",
              "      <td>annihilated</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ready to get annihilated for the BUCS game</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>443</td>\n",
              "      <td>apocalypse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>513</td>\n",
              "      <td>army</td>\n",
              "      <td>Studio</td>\n",
              "      <td>But if you build an army of 100 dogs and their...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>2619</td>\n",
              "      <td>crashed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVH...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>3640</td>\n",
              "      <td>desolation</td>\n",
              "      <td>Quilmes , Arg</td>\n",
              "      <td>This desperation dislocation\\nSeparation conde...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>3900</td>\n",
              "      <td>devastated</td>\n",
              "      <td>PG Chillin!</td>\n",
              "      <td>Man Currensy really be talkin that talk... I'd...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>4342</td>\n",
              "      <td>dust%20storm</td>\n",
              "      <td>chicago</td>\n",
              "      <td>Going to a fest? Bring swimming goggles for th...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>5781</td>\n",
              "      <td>forest%20fires</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Campsite recommendations \\nToilets /shower \\nP...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>6552</td>\n",
              "      <td>injury</td>\n",
              "      <td>Saint Paul</td>\n",
              "      <td>My prediction for the Vikings game this Sunday...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>6554</td>\n",
              "      <td>injury</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dante Exum's knee injury could stem Jazz's hop...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>6570</td>\n",
              "      <td>injury</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@Sport_EN Just being linked to Arsenal causes ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>6701</td>\n",
              "      <td>lava</td>\n",
              "      <td>Nashville, TN</td>\n",
              "      <td>Imagine a room with walls that are lava lamps.</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>6702</td>\n",
              "      <td>lava</td>\n",
              "      <td>probably watching survivor</td>\n",
              "      <td>The sunset looked like an erupting volcano ......</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>6729</td>\n",
              "      <td>lava</td>\n",
              "      <td>Clayton, NC</td>\n",
              "      <td>Check out my Lava lamp dude ???? http://t.co/T...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>6861</td>\n",
              "      <td>mass%20murder</td>\n",
              "      <td>i'm a Citizen of the World</td>\n",
              "      <td>If abortion is murder then blowjobs are cannib...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5068</th>\n",
              "      <td>7226</td>\n",
              "      <td>natural%20disaster</td>\n",
              "      <td>on to the next adventure</td>\n",
              "      <td>Of course the one day I have to dress professi...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "229    328  ...   True\n",
              "301    443  ...   True\n",
              "356    513  ...   True\n",
              "1822  2619  ...   True\n",
              "2536  3640  ...   True\n",
              "2715  3900  ...   True\n",
              "3024  4342  ...   True\n",
              "4068  5781  ...   True\n",
              "4609  6552  ...   True\n",
              "4611  6554  ...   True\n",
              "4622  6570  ...   True\n",
              "4713  6701  ...   True\n",
              "4714  6702  ...   True\n",
              "4732  6729  ...   True\n",
              "4820  6861  ...   True\n",
              "5068  7226  ...   True\n",
              "\n",
              "[16 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unqIyChnJ3vV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relabel_target( tweet_id , target ):\n",
        "    \n",
        "    if tweet_id in mislabelled_ids:\n",
        "        target = False\n",
        "\n",
        "    return target"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbBDmvD3J3va",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "a82f84d7-888b-4a39-e781-f5313d94080a"
      },
      "source": [
        "# reemplazo los targets que estan mislabeleados\n",
        "\n",
        "df_train['target'] = df_train.apply(lambda row: relabel_target(row[\"id\"], row['target']), axis=1)\n",
        "\n",
        "df_train.loc[ df_train['id'].isin(mislabelled_ids)]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>328</td>\n",
              "      <td>annihilated</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ready to get annihilated for the BUCS game</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>443</td>\n",
              "      <td>apocalypse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Short Reading\\n\\nApocalypse 21:1023 \\n\\nIn the...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>513</td>\n",
              "      <td>army</td>\n",
              "      <td>Studio</td>\n",
              "      <td>But if you build an army of 100 dogs and their...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1822</th>\n",
              "      <td>2619</td>\n",
              "      <td>crashed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My iPod crashed..... \\n#WeLoveYouLouis \\n#MTVH...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>3640</td>\n",
              "      <td>desolation</td>\n",
              "      <td>Quilmes , Arg</td>\n",
              "      <td>This desperation dislocation\\nSeparation conde...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2715</th>\n",
              "      <td>3900</td>\n",
              "      <td>devastated</td>\n",
              "      <td>PG Chillin!</td>\n",
              "      <td>Man Currensy really be talkin that talk... I'd...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3024</th>\n",
              "      <td>4342</td>\n",
              "      <td>dust%20storm</td>\n",
              "      <td>chicago</td>\n",
              "      <td>Going to a fest? Bring swimming goggles for th...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>5781</td>\n",
              "      <td>forest%20fires</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Campsite recommendations \\nToilets /shower \\nP...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4609</th>\n",
              "      <td>6552</td>\n",
              "      <td>injury</td>\n",
              "      <td>Saint Paul</td>\n",
              "      <td>My prediction for the Vikings game this Sunday...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>6554</td>\n",
              "      <td>injury</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dante Exum's knee injury could stem Jazz's hop...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4622</th>\n",
              "      <td>6570</td>\n",
              "      <td>injury</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@Sport_EN Just being linked to Arsenal causes ...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4713</th>\n",
              "      <td>6701</td>\n",
              "      <td>lava</td>\n",
              "      <td>Nashville, TN</td>\n",
              "      <td>Imagine a room with walls that are lava lamps.</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4714</th>\n",
              "      <td>6702</td>\n",
              "      <td>lava</td>\n",
              "      <td>probably watching survivor</td>\n",
              "      <td>The sunset looked like an erupting volcano ......</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4732</th>\n",
              "      <td>6729</td>\n",
              "      <td>lava</td>\n",
              "      <td>Clayton, NC</td>\n",
              "      <td>Check out my Lava lamp dude ???? http://t.co/T...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4820</th>\n",
              "      <td>6861</td>\n",
              "      <td>mass%20murder</td>\n",
              "      <td>i'm a Citizen of the World</td>\n",
              "      <td>If abortion is murder then blowjobs are cannib...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5068</th>\n",
              "      <td>7226</td>\n",
              "      <td>natural%20disaster</td>\n",
              "      <td>on to the next adventure</td>\n",
              "      <td>Of course the one day I have to dress professi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "229    328  ...  False\n",
              "301    443  ...  False\n",
              "356    513  ...  False\n",
              "1822  2619  ...  False\n",
              "2536  3640  ...  False\n",
              "2715  3900  ...  False\n",
              "3024  4342  ...  False\n",
              "4068  5781  ...  False\n",
              "4609  6552  ...  False\n",
              "4611  6554  ...  False\n",
              "4622  6570  ...  False\n",
              "4713  6701  ...  False\n",
              "4714  6702  ...  False\n",
              "4732  6729  ...  False\n",
              "4820  6861  ...  False\n",
              "5068  7226  ...  False\n",
              "\n",
              "[16 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kDXR8zGJ3vd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#----------WARNING---------------#\n",
        "\n",
        "# esta libreria solo se puede instalar si tenes JDK VERSION 8\n",
        "# si tenes cualquier otra version NO SE PUEDE INSTALAR\n",
        "\n",
        "# para instalarlo: \n",
        "# pip install pycontractions\n",
        "#from pycontractions import Contractions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tTksBarJ3vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Descomentar esta celda si se descarga PyContractions\n",
        "\n",
        "#cont = Contractions(api_key=\"glove-twitter-100\")\n",
        "#cont.load_models()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX2OsqLbJ3vi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_cont = df_train.copy()\n",
        "df_test_cont = df_test.copy()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVd-Ll-bJ3vk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dec0200d-cc1a-4938-bbee-2a9b6b66e968"
      },
      "source": [
        "#revisamos un tweet que tiene alguna contraccion\n",
        "df_train_cont.iloc[99,3]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"only had a car for not even a week and got in a fucking car accident .. Mfs can't fucking drive .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7fmP4YDJ3vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Descomentar esta celda si se descarga PyContractions\n",
        "\n",
        "#df_train_cont['text'] = list( cont.expand_texts(df_train_cont['text'].to_list()) )\n",
        "#df_test_cont['text'] = list( cont.expand_texts(df_test_cont['text'].to_list()) )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmwSZzHaJ3vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d44efd2a-d780-4c53-c192-3d0f6985f6e8"
      },
      "source": [
        "df_train_cont.iloc[99,3]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"only had a car for not even a week and got in a fucking car accident .. Mfs can't fucking drive .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCIKU4YUJ3vu",
        "colab_type": "text"
      },
      "source": [
        "#### reemplazo los urls presentes con \"URL\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TezOQTEiJ3vu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6263cd72-a701-4afc-cfae-f979035a04f6"
      },
      "source": [
        "df_train_cont.iloc[4732,3]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Check out my Lava lamp dude ???? http://t.co/To9ViqooFv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUGZrtA8J3vw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#patron que siguen los urls de los tweets\n",
        "pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+/(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+'\n",
        "\n",
        "def replace_urls(text):\n",
        " \n",
        "    replaced = re.sub(pattern, 'URL', text)\n",
        "    \n",
        "    return replaced"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiPrIZfYJ3vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_cont['text'] = df_train_cont['text'].apply(lambda x: replace_urls(x))\n",
        "\n",
        "df_test_cont['text'] = df_test_cont['text'].apply(lambda x: replace_urls(x))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-rxMsbZJ3v1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6ee915dc-b077-4389-9a52-ea8558bbeab5"
      },
      "source": [
        "df_train_cont.iloc[4732,3]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Check out my Lava lamp dude ???? URL'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7mqfsA0J3v4",
        "colab_type": "text"
      },
      "source": [
        "#### cuento la cantidad de palabras que tiene cada tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSYBQiUSJ3v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_count(text):\n",
        "    \n",
        "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
        "    words = tokenizer.tokenize(text)\n",
        "    return len(words)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjBjqj5XJ3v6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_cont['word_count'] = df_train_cont['text'].apply(lambda x: word_count(x))\n",
        "df_test_cont['word_count'] = df_test_cont['text'].apply(lambda x: word_count(x))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq-SJBoWJ3v9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "65e5187c-8d0a-42c2-ddc6-7e0044004ab3"
      },
      "source": [
        "df_train_cont.head(3)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>word_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>noKeyword</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>noKeyword</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>noKeyword</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id    keyword  ... target word_count\n",
              "0   1  noKeyword  ...   True         13\n",
              "1   4  noKeyword  ...   True          7\n",
              "2   5  noKeyword  ...   True         22\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DErh9oLNJ3v_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf1fc86c-1082-403f-a17c-c77ec47c8557"
      },
      "source": [
        "df_train_cont.iloc[4732,3]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Check out my Lava lamp dude ???? URL'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HYEy9W6J3wC",
        "colab_type": "text"
      },
      "source": [
        "nos interesaba contar los url como palabra, entonces decidimos eliminarlos despues de crear el 'word_count'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MomnpcBJ3wC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_urls(text):\n",
        "    \n",
        "    no_url = re.sub('URL', '', text)\n",
        "    \n",
        "    return no_url"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzNQdtC4J3wF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_cont['text'] = df_train_cont['text'].apply( lambda x: remove_urls(x) )\n",
        "df_test_cont['text'] = df_test_cont['text'].apply( lambda x: remove_urls(x) )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyP5k0l_J3wJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "98d98283-0ea6-48a3-86b2-db86db94225e"
      },
      "source": [
        "df_train_cont.iloc[4732,3]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Check out my Lava lamp dude ???? '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-XtQJNpJ3wM",
        "colab_type": "text"
      },
      "source": [
        "## Preprocesamiento de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bqMXhDSJ3wM",
        "colab_type": "text"
      },
      "source": [
        "### Limpieza de los text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1Av9bMBJ3wN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def procesar_slang(tweet):\n",
        "\n",
        "    \n",
        "    # remover caracteres especiales\n",
        "\n",
        "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
        "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
        "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
        "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
        "\n",
        "\n",
        "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
        "    \n",
        "\n",
        "    return tweet"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvsusNfWJ3wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    text = text.lower()\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    text = re.sub('[=><,*;_:#@&\\']', '',text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktY5fvjZJ3wR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_process_text(text):\n",
        "\n",
        "    tokenizer = TweetTokenizer(reduce_len=True,strip_handles=False)\n",
        "\n",
        "    processed_text = procesar_slang(text)\n",
        "    processed_text = clean_text(processed_text)\n",
        "    processed_text = tokenizer.tokenize(processed_text) \n",
        "    processed_text = ' '.join(processed_text)\n",
        "    \n",
        "    return processed_text"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ICRjc45J3wT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1ff034a4-30b4-4535-c325-ee07cc64b867"
      },
      "source": [
        "df_train_cont.iloc[0,3]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDhgsiKxJ3wW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_cont['text'] = df_train_cont['text'].apply(lambda x : pre_process_text(x))\n",
        "df_test_cont['text'] = df_test_cont['text'].apply(lambda x : pre_process_text(x))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htE6W7PhJ3wY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68afdd41-1c3d-4fa4-dcd4-a7fcc3f90dc0"
      },
      "source": [
        "df_train_cont.iloc[0,3]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'our deeds are the reason of this earthquake may allah forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2CbVimrJ3wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# para instalar textblob:  \n",
        "#pip install -U textblob\n",
        "\n",
        "#para instalar los datos para usar textblob: \n",
        "#python -m textblob.download_corpora\n",
        "\n",
        "from textblob import Word\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXWOG-XnJ3wc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def lematizar_texto(text):\n",
        "    \n",
        "    lem = []\n",
        "    \n",
        "    for i in text.split():\n",
        "        word1= Word(i).lemmatize(\"n\")\n",
        "        word2= Word(word1).lemmatize(\"v\")\n",
        "        word3= Word(word2).lemmatize(\"a\")\n",
        "        lem.append(Word(word3).lemmatize())\n",
        "    \n",
        "    lem_text = \" \".join(lem)\n",
        "    return lem_text"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Tfefg6jJ3we",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4403e033-8c34-4f61-cb11-ca4d3056cdb1"
      },
      "source": [
        "df_train_cont.iloc[99,3]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'only had a car for not even a week and got in a fucking car accident .. mfs cant fucking drive .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuQAudLMJ3wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e2efb882-eb44-4401-dcff-a91b41b12ac8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "df_train_cont['text'] = df_train_cont['text'].apply(lambda x: lematizar_texto(x))\n",
        "df_test_cont['text'] = df_test_cont['text'].apply(lambda x: lematizar_texto(x))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgypNx8AJ3wi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "90b97067-9615-4c40-9aea-ab4cb1b25cf5"
      },
      "source": [
        "df_train_cont.iloc[99,3]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'only have a car for not even a week and get in a fuck car accident .. mf cant fuck drive .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwqE12qGJ3wk",
        "colab_type": "text"
      },
      "source": [
        "------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PEXSOM9J3wl",
        "colab_type": "text"
      },
      "source": [
        "## Modelo Final: Red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaLTj_ZtJ3wm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, LSTM\n",
        "from keras.models import Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.layers import Input\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOAxzxCMJ3wo",
        "colab_type": "text"
      },
      "source": [
        "#### abrimos y preparamos el pre-trained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4ZF1kUMJ3wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# abro el pre-trained embedding y me creo un diccionario que contenga\n",
        "# todos sus elementos\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/drive/My Drive/datasetTPDatos/data/glove.twitter.27B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E-TyIKeJ3wr",
        "colab_type": "text"
      },
      "source": [
        "preparamos el texto del train para entrenar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiO2GQe0J3ws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# entreno el tokenizer con \n",
        "\n",
        "word_tok = Tokenizer(filters='=><*_,;:#@&\\'')\n",
        "\n",
        "word_tok.fit_on_texts(df_train_cont['text'])\n",
        "\n",
        "\n",
        "#defino el vocab length (cant. de unique words +1 )\n",
        "vocab_length = len(word_tok.word_index) + 1\n",
        "\n",
        "#encodeo los tweets\n",
        "embedded_train_text = word_tok.texts_to_sequences(df_train_cont['text'])\n",
        "\n",
        "#cuantas palabras tiene el tweet mas largo\n",
        "longest_text = max( df_train_cont['word_count'] )\n",
        "\n",
        "#agrego padding para que la longitud de todos los tweets sea de 'longest_text'\n",
        "padded_train_text = pad_sequences(embedded_train_text, longest_text, padding='post')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gx_hlBVFJ3ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creo la matriz de weights, que solo contiene los embeddings\n",
        "# de las palabras que hay en el X_train\n",
        "\n",
        "weights_matrix = np.zeros((vocab_length, 100))\n",
        "\n",
        "for word, index in word_tok.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    \n",
        "    if embedding_vector is not None:\n",
        "        weights_matrix[index] = embedding_vector"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woHV6gkJJ3wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#casteo el target a int\n",
        "targets = df_train_cont['target'].astype(int)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8_OdHiHJ3w1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "embedding_layer = Embedding(vocab_length, 100, weights=[weights_matrix], input_length=longest_text, trainable=True)\n",
        "\n",
        "model.add(embedding_layer)\n",
        "model.add(Bidirectional(LSTM(6, dropout= 0.2)))\n",
        "\n",
        "model.add(Dense(units=3, activation='relu'))\n",
        "model.add(Dense(units=3, activation='relu'))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRFCBtlgJ3w3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "6916e13c-9dfa-4f9f-dbfe-f6a9464dca76"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 34, 100)           1373800   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 12)                5136      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 39        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 12        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 4         \n",
            "=================================================================\n",
            "Total params: 1,378,991\n",
            "Trainable params: 1,378,991\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHB4PJoLJ3w8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "4a98feec-7fc5-4cb8-ab58-bdba59c320d5"
      },
      "source": [
        "model.fit(padded_train_text, targets, epochs=4, verbose=1)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "238/238 [==============================] - 12s 50ms/step - loss: 0.5993 - acc: 0.7045\n",
            "Epoch 2/4\n",
            "238/238 [==============================] - 12s 50ms/step - loss: 0.4781 - acc: 0.8126\n",
            "Epoch 3/4\n",
            "238/238 [==============================] - 12s 52ms/step - loss: 0.3894 - acc: 0.8534\n",
            "Epoch 4/4\n",
            "238/238 [==============================] - 12s 51ms/step - loss: 0.3145 - acc: 0.8824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32b7973780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtDOym5VJ3w-",
        "colab_type": "text"
      },
      "source": [
        "le doy formato al texto del test para poder predecir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEjaNf9QJ3w-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_test = word_tok.texts_to_sequences(df_test_cont['text'])\n",
        "padded_test = pad_sequences(embedding_test, longest_text, padding='post')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1EDdobmJ3xB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3383db14-138c-47da-c0ec-867f30fe5192"
      },
      "source": [
        "predictions = model.predict_classes(padded_test)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-47-2fb0c935a54d>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMI66eaGJ3xE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#las predictions es un array de listas, donde cada una tiene la prediccion,\n",
        "# aca lo convertimos en una sola lista que contiene todas las predicciones\n",
        "predictions.tolist()\n",
        "form_predictions =[]\n",
        "\n",
        "for pred in predictions:\n",
        "    for target in pred:\n",
        "        form_predictions.append(target)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgqOV2PUJ3xI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "92032148-15f8-458d-f7ea-e4bd151d4c2a"
      },
      "source": [
        "# le doy el formato que pide kaggle y guardo el csv\n",
        "from google.colab import files\n",
        "pred = pd.DataFrame()\n",
        "pred['id'] = df_test_cont['id']\n",
        "pred['target'] = form_predictions\n",
        "pred\n",
        "\n",
        "pred.to_csv('resultKeras.csv',index=False)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       1\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       1\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    }
  ]
}